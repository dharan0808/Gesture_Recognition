{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a358a898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27095676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dharan\\OneDrive\\Documents\\SkillCraft Tasks\\Task 4\\SCT_ML_4\\Notebook\n"
     ]
    }
   ],
   "source": [
    "# VIDEO_DIR = Path(\"data/videos\")\n",
    "# FRAME_OUTPUT_DIR = Path(\"data/frames\")\n",
    "# NUM_FRAMES = 20\n",
    "# RESIZE_DIMS = (128, 128)\n",
    "\n",
    "# def extract_frames_from_video(video_path, num_frames, resize_dims):\n",
    "#     cap = cv2.VideoCapture(str(video_path))\n",
    "#     total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "#     if total_frames < num_frames:\n",
    "#         raise ValueError(f\"Video {video_path} has fewer than {num_frames} frames.\")\n",
    "\n",
    "#     frame_indices = [int(i * total_frames / num_frames) for i in range(num_frames)]\n",
    "#     frames = []\n",
    "#     current_idx = 0\n",
    "#     read_idx = 0\n",
    "\n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "\n",
    "#         if read_idx == frame_indices[current_idx]:\n",
    "#             resized = cv2.resize(frame, resize_dims)\n",
    "#             frames.append(resized)\n",
    "#             current_idx += 1\n",
    "#             if current_idx >= len(frame_indices):\n",
    "#                 break\n",
    "\n",
    "#         read_idx += 1\n",
    "\n",
    "#     cap.release()\n",
    "#     return frames\n",
    "\n",
    "# # === Frame Extraction ===\n",
    "# gesture_classes = sorted([f.name for f in VIDEO_DIR.iterdir() if f.is_dir()])\n",
    "\n",
    "# for gesture in gesture_classes:\n",
    "#     (FRAME_OUTPUT_DIR / gesture).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#     gesture_video_dir = VIDEO_DIR / gesture\n",
    "#     gesture_output_dir = FRAME_OUTPUT_DIR / gesture\n",
    "\n",
    "#     for video_file in os.listdir(gesture_video_dir):\n",
    "#         if not video_file.endswith(\".mp4\"):\n",
    "#             continue\n",
    "\n",
    "#         video_path = gesture_video_dir / video_file\n",
    "#         output_subdir = gesture_output_dir / video_file.replace(\".mp4\", \"\")\n",
    "#         output_subdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#         print(f\"Processing video: {video_file}...\")\n",
    "\n",
    "#         try:\n",
    "#             frames = extract_frames_from_video(video_path, NUM_FRAMES, RESIZE_DIMS)\n",
    "#             for idx, frame in enumerate(frames):\n",
    "#                 frame_path = output_subdir / f\"{idx:03d}.jpg\"\n",
    "#                 cv2.imwrite(str(frame_path), frame)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Failed to process {video_file}: {e}\")\n",
    "\n",
    "# print(\"Frame extraction completed.\")\n",
    "\n",
    "print(os.listdir(\"data\"))  # should print: ['videos']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
